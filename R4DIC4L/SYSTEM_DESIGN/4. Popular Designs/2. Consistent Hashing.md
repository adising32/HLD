---
noteID: 0a4bf8ef-13a8-40e8-af5a-8487d7335498
---
##### Problem with Mod hashing
If you have n cache servers, a common way to balance the load is to use the following hash method:
serverIndex = hash(key) % N, where N is the size of the server pool.
This approach works well when the size of the server pool is fixed, and the data distribution is even. However, problems arise when new servers are added, or existing servers are removed. Applying modular operation gives us different server indexes. This causes a storm of cache misses.

![[mod-hashing.png]]
In the above example, when there were 4 servers, the corresponding keys were cached in the cache servers. Once we removed a cache server, then the load balancer function changed to ID % 3. This caused a the requests to be redistributed and almost all resulted in cache misses. Now not only the keys present in server 4, but almost all the ids needs to be redistributed among the cache servers.


##### Consistent Hashing
Consistent hashing is a special kind of hashing such that when a hash table is re-sized and consistent hashing is used, only k/n keys need to be remapped on average, where k is the number of keys, and n is the number of slots.

**Hash ring** : Assume SHA-1 is used as the hash function f, and the output range of the hash function is: x0, x1, x2, x3, ..., xn. In cryptography, SHA-1’s hash space goes from 0 to 2^160 - 1. By collecting both ends, we get a hash ring.

**Hash Servers** : Using the same hash function f, we map servers based on server IP or name onto the ring.

**Hash Keys** : Cache keys are mapped on to the hash ring similar to hash servers.

**Server Lookup** : To determine which server a key is stored on, we go clockwise from the key position on the ring until a server is found.
![[consistent-hashing.png]]
**Adding a server** : Adding a new server will only require redistribution of a fraction of keys. If a new server (Server 5) is added between key 4 and server 4 then only key 4 needs to be remapped to server 5. 

**Removing a Server** : Similarly if Server 4 is removed only key4 will be remapped to Server 1.

#### Problems
Two problems are identified with this approach. First, it is impossible to keep the same size of partitions on the ring for all servers considering a server can be added or removed. A partition is the hash space between adjacent servers.
Second, it is possible to have a non-uniform key distribution on the ring.

**Virtual Nodes** : A virtual node refers to the real node, and each server is represented by multiple virtual nodes on the ring.With virtual nodes, each server is responsible for multiple partitions. To find which server a key is stored on, we go clockwise from the key’s location and find the first virtual node encountered on the ring. As the number of virtual nodes increases, the distribution of keys becomes more balanced.

**Simple Implementation**

```
import java.util.Collection;  
import java.util.SortedMap;  
import java.util.TreeMap;  
  
public class ConsistentHash<T> {  
  
  private final HashFunction hashFunction;  
  private final int numberOfReplicas;  
  private final SortedMap<Integer, T> circle =  
    new TreeMap<Integer, T>();  
  
  public ConsistentHash(HashFunction hashFunction,  
    int numberOfReplicas, Collection<T> nodes) {  
  
    this.hashFunction = hashFunction;  
    this.numberOfReplicas = numberOfReplicas;  
  
    for (T node : nodes) {  
      add(node);  
    }  
  }  
  
  public void add(T node) {  
    for (int i = 0; i < numberOfReplicas; i++) {  
      circle.put(hashFunction.hash(node.toString() + i),  
        node);  
    }  
  }  
  
  public void remove(T node) {  
    for (int i = 0; i < numberOfReplicas; i++) {  
      circle.remove(hashFunction.hash(node.toString() + i));  
    }  
  }  
  
  public T get(Object key) {  
    if (circle.isEmpty()) {  
      return null;  
    }  
    int hash = hashFunction.hash(key);  
    if (!circle.containsKey(hash)) {  
      SortedMap<Integer, T> tailMap =  
        circle.tailMap(hash);  
      hash = tailMap.isEmpty() ?  
             circle.firstKey() : tailMap.firstKey();  
    }  
    return circle.get(hash);  
  }   
  
}
```

