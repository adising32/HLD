---
noteID: eb750ae8-0471-4efc-a30a-0f9738daa2e3
---
#### API Gateway
API gateway is a fully managed service that supports rate limiting, SSL termination, authentication, IP whitelisting, servicing static content, etc.


#### Token bucket algorithm
A token bucket is a container that has pre-defined capacity. Tokens are put in the bucket at preset rates periodically. Once the bucket is full, no more tokens are added. Each request consumes one token. When a request arrives, we check if there are enough tokens in the bucket. If there are enough tokens, we take one token out for each request, and the request goes through. If there are not enough tokens, the request is dropped.
![[token-bucket.png]]
#### Leaking Bucket algorithm
The leaking bucket algorithm is similar to the token bucket except that requests are processed at a fixed rate. It is usually implemented with a first-in-first-out (FIFO) queue. The algorithm works as follows:
- When a request arrives, the system checks if the queue is full. If it is not full, the request is added to the queue.
- Otherwise, the request is dropped.  
- Requests are pulled from the queue and processed at regular intervals.
![[leaking-bucket.png]]
#### Fixed window counter algorithm
The algorithm divides the timeline into fix-sized time windows and assign a counter for each window. Each request increments the counter by one. Once the counter reaches the pre-defined threshold, new requests are dropped until a new time window starts. A major problem with this algorithm is that a burst of traffic at the edges of time windows could cause more requests than allowed quota to go through.

#### Sliding window log algorithm
The sliding window log algorithm fixes the above issue. The algorithm keeps track of request timestamps. Timestamp data is usually kept in cache, such as sorted sets of Redis. When a new request comes in, remove all the outdated timestamps. Outdated timestamps are defined as those older than the start of the current time window. Add timestamp of the new request to the log. If the log size is the same or lower than the allowed count, a request is accepted. Otherwise, it is rejected.
The algorithm consumes a lot of memory because even if a request is rejected, its timestamp might still be stored in memory.

### High Level Design

##### Counter In Memory Storage
 Need a counter to keep track of how many requests are sent from the same user, IP address, etc. If the counter is larger than the limit, the request is disallowed. In-memory cache is chosen because it is fast and supports time-based expiration strategy.
##### Configurations
We need configurations that define the rate limiter behavior which can be stored on disc and can be cached.
##### Exceeding the rate limit
In case a request is rate limited, APIs return a HTTP response code 429 (too many requests) to the client. Depending on the use cases, we may enqueue the rate-limited requests to be processed later. Response header may contain **X-Ratelimit-Remaining** , **X-Ratelimit-Limit** , **X-Ratelimit-Retry-After** .
![[rate-limiter-hld.png]]

